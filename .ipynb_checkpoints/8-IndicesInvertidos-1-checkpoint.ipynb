{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d22675",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\">\n",
    "    <img src=\"data:image/svg+xml,%3Csvg%20version%3D%221.2%22%20baseProfile%3D%22tiny%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20136.5%2058%22%20height%3D%2250%22%20overflow%3D%22visible%22%20xml%3Aspace%3D%22preserve%22%3E%3Cg%20fill%3D%22%23141819%22%3E%3Cpath%20d%3D%22M0%2033.4h1v6.3c0%201.1.5%201.7%201.7%201.7s1.7-.5%201.7-1.7v-6.3h1v6.3c0%201.8-1%202.5-2.7%202.5-1.7.1-2.7-.7-2.7-2.5v-6.3zM8.1%2042.2v-8.8h1.3l3.2%207h.1v-7h1v8.8h-1.3l-3.3-7.3H9v7.3zM16.5%2033.4h1v8.7h-1zM24.4%2033.4h1l-2.3%208.8h-1.4l-2.3-8.8h1.1l1.9%207.5h.1zM27.4%2042.2v-8.8h4.7v.9h-3.7v2.9h3.2v.9h-3.2v3.2h3.9v.9zM35.3%2037.6h1.8c1.1%200%201.6-.5%201.6-1.6s-.5-1.6-1.6-1.6h-1.8v3.2zm0%204.6h-1v-8.7h3c1.6%200%202.5.9%202.5%202.5%200%201.3-.6%202-1.2%202.3l1.3%203.9h-1.1l-1.2-3.6h-2.3v3.6zM46.7%2035.6c-.1-1-.6-1.4-1.7-1.4-1%200-1.7.4-1.7%201.4%200%201%20.8%201.2%201.9%201.6%201.4.4%202.7.9%202.7%202.6%200%201.7-1.1%202.5-2.8%202.5-1.8%200-2.8-.8-2.9-2.5l1-.1c.1%201.2.7%201.7%201.9%201.7%201.1%200%201.8-.5%201.8-1.5s-.6-1.3-1.9-1.7c-1.4-.4-2.6-.8-2.6-2.5s1.1-2.4%202.8-2.4c1.6%200%202.6.6%202.8%202.2l-1.3.1zM50.2%2033.4h1v8.7h-1zM55%2041.3h1.9c1%200%201.7-.5%201.7-1.5v-4c0-1-.6-1.5-1.7-1.5H55v7zm-1-7.9h2.8c1.8%200%202.8.7%202.8%202.5v3.7c0%201.8-1%202.5-2.8%202.5H54v-8.7zM63.2%2039.1H66l-1.3-4.6h-.1l-1.4%204.6zm-.8%203.1h-1.1l2.6-8.7h1.5l2.6%208.7h-1.1l-.6-2.2H63l-.6%202.2zM70.9%2041.3h1.9c1%200%201.7-.5%201.7-1.5v-4c0-1-.6-1.5-1.7-1.5h-1.9v7zm-1.1-7.9h2.8c1.8%200%202.8.7%202.8%202.5v3.7c0%201.8-1%202.5-2.8%202.5h-2.8v-8.7zM81.3%2042.2v-8.8h1.3l3.2%207h.1v-7h1v8.8h-1.3l-3.3-7.3h-.1v7.3zM90.7%2039.1h2.8l-1.3-4.6H92l-1.3%204.6zm-.9%203.1h-1.1l2.6-8.7h1.5l2.6%208.7h-1.1l-.6-2.2h-3.3l-.6%202.2zM101.2%2036.1v-.4c0-1.1-.5-1.5-1.7-1.5-1.1%200-1.8.4-1.8%201.5v4.1c0%201.1.6%201.5%201.8%201.5%201.1%200%201.7-.5%201.7-1.5v-.4l1%20.1v.1c0%201.8-.9%202.6-2.7%202.6-1.8%200-2.8-.7-2.8-2.5v-4c0-1.8%201-2.5%202.8-2.5%201.8%200%202.7.7%202.7%202.6v.2l-1%20.1zM104.7%2033.4h1v8.7h-1zM109.3%2039.9c0%201.1.7%201.5%201.8%201.5s1.8-.4%201.8-1.5v-4.1c0-1.1-.7-1.5-1.8-1.5s-1.8.4-1.8%201.5v4.1zm-1-4.1c0-1.9%201-2.5%202.8-2.5%201.8%200%202.8.7%202.8%202.5v3.9c0%201.9-1%202.5-2.8%202.5-1.8%200-2.8-.7-2.8-2.5v-3.9zM116.5%2042.2v-8.8h1.3l3.2%207h.1v-7h.9v8.8h-1.2l-3.3-7.3h-.1v7.3zM125.9%2039.1h2.8l-1.3-4.6h-.1l-1.4%204.6zm-.9%203.1h-1.1l2.6-8.7h1.5l2.6%208.7h-1.1l-.6-2.1h-3.3l-.6%202.1zM132.5%2042.2v-8.8h1v7.9h3v.9zM1.2%2057h1.9c1%200%201.7-.5%201.7-1.5v-4c0-1-.6-1.5-1.7-1.5H1.2v7zM.1%2049.1H3c1.8%200%202.8.7%202.8%202.5v3.7c0%201.8-1%202.5-2.8%202.5H.1v-8.7zM8.3%2057.9v-8.8H13v.9H9.3v2.9h3.3v.9H9.3V57h3.9v.9zM19.7%2050.1h-2.1v-1h5.1v1h-2v7.8h-1zM25.6%2053.3h1.8c1.1%200%201.6-.5%201.6-1.6s-.5-1.6-1.6-1.6h-1.8v3.2zm0%204.6h-1v-8.7h3c1.6%200%202.5.9%202.5%202.5%200%201.3-.6%202-1.2%202.3l1.3%203.9h-1.1l-1.2-3.6h-2.3v3.6zM32.8%2057.9v-8.8h4.7v.9h-3.7v2.9H37v.9h-3.2V57h3.9v.9zM44%2051.3c-.1-1-.6-1.4-1.7-1.4-1%200-1.7.4-1.7%201.4%200%201%20.8%201.2%201.9%201.6%201.4.4%202.7.9%202.7%202.6%200%201.7-1.1%202.5-2.8%202.5-1.8%200-2.8-.8-2.9-2.5l1-.1c.1%201.2.7%201.7%201.9%201.7%201.1%200%201.8-.5%201.8-1.5s-.6-1.3-1.9-1.7c-1.4-.4-2.6-.8-2.6-2.5s1.1-2.4%202.8-2.4c1.6%200%202.6.6%202.8%202.2l-1.3.1zM51.8%2057h1.9c1.1%200%201.7-.5%201.7-1.5v-4c0-1-.6-1.5-1.7-1.5h-1.9v7zm-1-7.9h2.8c1.8%200%202.8.7%202.8%202.5v3.7c0%201.8-1%202.5-2.8%202.5h-2.8v-8.7zM58.9%2057.9v-8.8h4.7v.9h-3.7v2.9h3.3v.9h-3.3V57h3.9v.9zM69.2%2057.9v-8.8h4.4v.9h-3.4v2.9h3v.9h-3v4.1zM75.6%2057.9v-8.8h4.7v.9h-3.7v2.9h3.2v.9h-3.2V57h3.9v.9zM83.5%2057h2.1c1.1%200%201.7-.6%201.7-1.6%200-1.1-.6-1.6-1.7-1.6h-2V57zm0-4.1h2c1%200%201.5-.5%201.5-1.4%200-1-.5-1.4-1.5-1.4h-2v2.8zm-1-3.8h3.3c1.6%200%202.3.7%202.3%202.2%200%201-.3%201.6-1%201.9v.1c.6.2%201.2.9%201.2%202.1%200%201.5-.7%202.4-2.4%202.4h-3.4v-8.7zM91.9%2053.3h1.8c1.1%200%201.6-.5%201.6-1.6s-.5-1.6-1.6-1.6h-1.8v3.2zm0%204.6h-1v-8.7h3c1.6%200%202.5.9%202.5%202.5%200%201.3-.6%202-1.2%202.3l1.3%203.9h-1.1l-1.2-3.6h-2.3v3.6zM99%2057.9v-8.8h4.7v.9H100v2.9h3.3v.9H100V57h3.9v.9zM107%2053.3h1.8c1.1%200%201.6-.5%201.6-1.6s-.5-1.6-1.6-1.6H107v3.2zm0%204.6h-1v-8.7h3c1.6%200%202.5.9%202.5%202.5%200%201.3-.6%202-1.2%202.3l1.3%203.9h-1.1l-1.2-3.6H107v3.6zM114.9%2055.6c0%201.1.7%201.5%201.8%201.5s1.8-.4%201.8-1.5v-4.1c0-1.1-.7-1.5-1.8-1.5s-1.8.4-1.8%201.5v4.1zm-1-4.1c0-1.9%201-2.5%202.8-2.5%201.8%200%202.8.7%202.8%202.5v3.9c0%201.9-1%202.5-2.8%202.5-1.8%200-2.8-.7-2.8-2.5v-3.9zM0%2023.7h96.4v3.6H0zM69.1%2017.5V0h11.5v2.9h-8V7h7.3v2.9h-7.3v4.7H81v2.9H69.1zm16.2%200V0h11v2.9h-7.6V7h6.9v2.9h-6.9v7.6h-3.4zm-30.8%200H51V0h7.2C62.1%200%2064%201.8%2064%205.3c0%202.8-1.4%204.1-2.7%204.6l2.9%207.6h-3.8l-2.4-7h-3.5v7zm0-9.8h2.9c2%200%203-.6%203-2.5s-1-2.5-3-2.5h-2.9v5zM39.9%202.9h-4.4V0h12.4v2.9h-4.4v14.6H40V2.9zM18.8%2017.5V0h4.1l5.8%2011.7h.2V0h3.4v17.5h-4L22.2%205.3H22v12.2h-3.2zM.1%200h3.5v12.1c0%202%201%202.8%203%202.8s3-.8%203-2.8V0h3.5v12.1c0%203.8-2.3%205.7-6.5%205.7S.1%2015.9.1%2012.1V0z%22%2F%3E%3C%2Fg%3E%3C%2Fsvg%3E\" />\n",
    "</p>\n",
    "\n",
    "<h2 style=\"text-align: center\">Estructura de Datos</h2>\n",
    "<h3 style=\"text-align: center\">Índices Invertidos: Construcción y Consultas</h3>\n",
    "<h3 style=\"text-align: center\">Guía de Ejercicios</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37c6b2",
   "metadata": {},
   "source": [
    "#### Ejercicio 1:\n",
    "\n",
    "Supongamos que queremos indexar una colección de documentos de texto, donde cada documento es un archivo de texto plano dentro de un directorio específico. Implementar una clase denominada IndiceInvertido que permita construir un índice invertido a partir de estos documentos y realizar consultas simples. El constructor de la clase debe aceptar la ruta del directorio que contiene los documentos y una función de tokenización opcional. Si no se proporciona una función de tokenización, se debe utilizar una función predeterminada que divida el texto en palabras basándose en espacios en blanco y elimine signos de puntuación. (En un ejercicio posterior, implementaremos una función de tokenización para otros tipos de entradas por ejemplo archivos html). No indexar stop words (usar nltk.corpus.stopwords.words('spanish') para obtener una lista de stop words en español). Si el constructor no encuentra los archivos en la ruta especificada, debe lanzar una excepción ValueError con un mensaje adecuado.\n",
    "\n",
    "```python\n",
    "def tokenizar(texto: str) -> list[str]:\n",
    "    \"\"\" Es una función que recibe un bloque de texto y devuelve una lista de tokens (palabras) normalizados (palabras en minúsculas y sin signos de puntuación, solo debe aceptar letras, números, punto (.), guión bajo (_), y guión (-) como parte de la palabra).\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "> **Nota:** Suponemos que el índice invertido cabe en memoria y por lo tanto se puede usar diccionarios de Python para implementarlo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77512cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "\n",
    "# ensure stopwords corpus is available\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "def normalizar(texto: str) -> str:\n",
    "    \"\"\"Normaliza Unicode (NFC) y aplica casefold para manejo correcto de mayúsculas/minúsculas y caracteres como ñ y vocales con tilde.\"\"\"\n",
    "    if texto is None:\n",
    "        return ''\n",
    "    return unicodedata.normalize('NFC', texto).casefold()\n",
    "\n",
    "def tokenizar(texto):\n",
    "    \"\"\"Devuelve lista de tokens normalizados (casefold).\n",
    "    Acepta letras (incluyendo acentuadas y ñ), números, punto, guión bajo y guión medio en las palabras.\n",
    "    No filtra stopwords (ese filtrado se hace en el constructor del índice).\n",
    "    \"\"\"\n",
    "    texto_norm = normalizar(texto)\n",
    "    # incluir ASCII letters, digits, punto, guión bajo, guión medio y rango latino acentuado \\u00C0-\\u017F\n",
    "    pattern = r'[A-Za-z0-9._\\-\\u00C0-\\u017F]+'\n",
    "    return [m.group(0) for m in re.finditer(pattern, texto_norm)]\n",
    "\n",
    "class IndiceInvertido:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ruta = \"./datos/8_IndicesInvertidos/libros\"\n",
    "    try:\n",
    "        indice = IndiceInvertido(ruta)\n",
    "    except ValueError as e:\n",
    "        print(\"No se pudo construir el índice:\", e)\n",
    "        return\n",
    "\n",
    "    print(indice)  # resumen básico\n",
    "    print(f\"Documentos indexados ({len(indice.docs)}): {sorted(indice.docs)}\\n\")\n",
    "\n",
    "    # Mostrar los 10 términos con mayor número de documentos (df)\n",
    "    top_terms = sorted(indice.index.items(), key=lambda kv: len(kv[1]), reverse=True)[:10]\n",
    "    print(\"Top 10 términos por número de documentos (term -> df):\")\n",
    "    for term, postings in top_terms:\n",
    "        print(f\"  {term} -> {len(postings)}\")\n",
    "    print()\n",
    "\n",
    "    if top_terms:\n",
    "        ejemplo = top_terms[0][0]\n",
    "        print(f\"Postings para el término más frecuente '{ejemplo}':\")\n",
    "        indice.mostrar_postings(ejemplo)\n",
    "        print()\n",
    "\n",
    "    # Pruebas de búsqueda y consultas\n",
    "    termos_prueba = [t[0] for t in top_terms[:3]]\n",
    "    print(\"Términos de prueba:\", termos_prueba)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff71125",
   "metadata": {},
   "source": [
    "#### Ejercicio 2:\n",
    "\n",
    "Escribir una función consulta que reciba una expresión booleana simple, compuesta por términos y los operadores AND, OR y NOT (por ejemplo: \"palabra1 AND palabra2\", \"palabra3 OR palabra4\", \"palabra5 AND NOT palabra6\"), y devuelva la lista de documentos que satisfacen la consulta. La función debe manejar correctamente la precedencia de los operadores (NOT tiene mayor precedencia que AND, que a su vez tiene mayor precedencia que OR). Si la consulta contiene términos que no están en el índice, deben ser tratados como si no aparecieran en ningún documento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fad499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolución Ejercicio 2\n",
    "def consulta(indice, expresion):\n",
    "    \"\"\"\n",
    "    Realiza una consulta booleana (AND, OR, NOT) sobre el índice invertido.\n",
    "    NOT tiene mayor precedencia que AND, que tiene mayor precedencia que OR.\n",
    "    Se soportan paréntesis. Devuelve la lista ordenada de documentos resultado.\n",
    "    \"\"\"\n",
    "    # precedencias\n",
    "    prec = {'NOT': 3, 'AND': 2, 'OR': 1}\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701eaf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso de la función consulta\n",
    "indice = IndiceInvertido(\"./datos/8_IndicesInvertidos/libros\")\n",
    "resultado = consulta(indice, \"amor AND NOT guerra\")\n",
    "print(\"Documentos que satisfacen la consulta:\", resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7142e",
   "metadata": {},
   "source": [
    "#### Ejercicio 3:\n",
    "Escribir un tokenizador que procese archivos HTML. El tokenizador debe extraer el texto visible del HTML solamente de <title> y <body>. Debe usar beautifulsoup4 para el procesamiento del HTML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a4e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def tokenizar_html(texto: str) -> list[str]:\n",
    "    \"\"\"Extrae texto visible de <title> y <body> de un HTML y devuelve tokens normalizados.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74385b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ruta = \"./datos/8_IndicesInvertidos/html_libros\"\n",
    "    try:\n",
    "        indice = IndiceInvertido(ruta, tokenizer=tokenizar_html)\n",
    "    except ValueError as e:\n",
    "        print(\"No se pudo construir el índice:\", e)\n",
    "        return\n",
    "\n",
    "    print(indice)  # resumen básico\n",
    "    print(f\"Documentos indexados ({len(indice.docs)}): {sorted(indice.docs)}\\n\")\n",
    "\n",
    "    # Mostrar los 10 términos con mayor número de documentos (df)\n",
    "    top_terms = sorted(indice.index.items(), key=lambda kv: len(kv[1]), reverse=True)[:10]\n",
    "    print(\"Top 10 términos por número de documentos (term -> df):\")\n",
    "    for term, postings in top_terms:\n",
    "        print(f\"  {term} -> {len(postings)}\")\n",
    "    print()\n",
    "\n",
    "    if top_terms:\n",
    "        ejemplo = top_terms[0][0]\n",
    "        print(f\"Postings para el término más frecuente '{ejemplo}':\")\n",
    "        indice.mostrar_postings(ejemplo)\n",
    "        print()\n",
    "\n",
    "    # Pruebas de búsqueda y consultas\n",
    "    termos_prueba = [t[0] for t in top_terms[:3]]\n",
    "    print(\"Términos de prueba:\", termos_prueba)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_html = IndiceInvertido(\"./datos/8_IndicesInvertidos/html_libros\", tokenizer=tokenizar_html)\n",
    "resultado = consulta(indice_html, \"amor AND NOT guerra\")\n",
    "print(\"Documentos que satisfacen la consulta:\", resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c1a2f6",
   "metadata": {},
   "source": [
    "#### Ejercicio 4:\n",
    "En ./datos/8_IndicesInvertidos/tweets/tweets.csv se encuentra un conjunto de tweets en español. Cada línea del archivo contiene un tweet con el siguiente formato: user,text,date,emotion,sentiment \n",
    "Cada tweet puede estar más de una vez en el archivo, la forma de identificar un tweet es por la combinación (user,date).\n",
    "Se pide modificar el índice invertido del ejercicio 1 para que pueda indexar estos tweets. El tokenizador debe eliminar menciones (palabras que comienzan con @), hashtags (palabras que comienzan con #), URLs y signos de puntuación. Además, debe normalizar las palabras a minúsculas y eliminar stop words en español. \n",
    "\n",
    "Debe incluir una función que permite buscar una palabra y devuelva una lista de tuplas (user, texto, [(emotion, sentiment)]) donde cada tupla corresponde a un tweet que contiene la palabra buscada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "\n",
    "# asegurarse de tener stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "def normalizar(texto: str) -> str:\n",
    "    if texto is None:\n",
    "        return ''\n",
    "    return unicodedata.normalize('NFC', texto).casefold()\n",
    "\n",
    "def tokenizar_tweet(texto: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Tokenizador para tweets:\n",
    "    - Normaliza a casefold y NFC.\n",
    "    - Elimina URLs, menciones (@...), hashtags (#...).\n",
    "    - Extrae tokens compuestos por letras (incluyendo acentuadas), números, punto, guión bajo y guión medio.\n",
    "    NOTA: No elimina stopwords; ese filtrado lo realiza la clase IndiceInvertidoTweets.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class IndiceInvertidoTweets:\n",
    "    \"\"\"\n",
    "    Índice invertido especializado para ./datos/8_IndicesInvertidos/tweets/tweets.csv\n",
    "    Cada línea CSV: user,text,date,emotion,sentiment\n",
    "    Identificador único de tweet: (user, date)\n",
    "    Al indexar, se asocian a cada (user,date) las tuplas (emotion, sentiment) encontradas.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_tweets = IndiceInvertidoTweets(\"./datos/8_IndicesInvertidos/tweets/tweets.csv\")\n",
    "resultados = indice_tweets.buscar_palabra(\"felicidad\")\n",
    "for tweet in resultados:\n",
    "    print(f\"Autor: {tweet[0]}, \\nTexto: {tweet[1]}, \\nEmociones y Sentimientos: {tweet[2]}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
